import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import os
import argparse
import json


class PaperSimilarity:
    def __init__(self, data_path, text_field="combined"):
        """
        åˆå§‹åŒ–
        :param data_path: CSV æˆ– JSON è·¯å¾„
        :param text_field: ä½¿ç”¨ 'title', 'abstract', æˆ– 'combined'ï¼ˆé»˜è®¤ï¼‰
        """
        self.data_path = data_path
        self.text_field = text_field
        self.df = self._load_data()
        self.texts = self._prepare_texts()

    def _load_data(self):
        if self.data_path.endswith(".csv"):
            df = pd.read_csv(self.data_path)
        elif self.data_path.endswith(".json"):
            df = pd.read_json(self.data_path, lines=False)
        else:
            raise ValueError("ä»…æ”¯æŒ .csv æˆ– .json æ–‡ä»¶")
        assert "id" in df.columns and "title" in df.columns and "abstract" in df.columns
        return df

    def _prepare_texts(self):
        if self.text_field == "title":
            return self.df["title"].fillna("").tolist()
        elif self.text_field == "abstract":
            return self.df["abstract"].fillna("").tolist()
        elif self.text_field == "combined":
            # æ ‡é¢˜æƒé‡æ›´é«˜ï¼šé‡å¤ä¸€æ¬¡æ ‡é¢˜
            return (
                self.df["title"].fillna("")
                + " "
                + self.df["title"].fillna("")
                + " "
                + self.df["abstract"].fillna("")
            ).tolist()
        else:
            raise ValueError("text_field å¿…é¡»æ˜¯ 'title', 'abstract', æˆ– 'combined'")

    # ================ æ–¹æ³•1ï¼šTF-IDF å¿«é€Ÿæ‰¹é‡ç­›é€‰ ================
    def compute_tfidf_similarity(self, top_k=10, threshold=0.5, output_path=None):
        """
        ä½¿ç”¨ TF-IDF + ä½™å¼¦ç›¸ä¼¼åº¦å¿«é€Ÿè®¡ç®—ç›¸ä¼¼è®ºæ–‡
        :param top_k: æ¯ç¯‡è®ºæ–‡è¿”å›æœ€ç›¸ä¼¼çš„ top_k ç¯‡
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä½äºåˆ™å¿½ç•¥ï¼‰
        :param output_path: ä¿å­˜ç»“æœè·¯å¾„ï¼ˆJSONï¼‰
        :return: list of dict, each: {'id1', 'id2', 'similarity'}
        """
        print("ğŸš€ æ­£åœ¨è®¡ç®— TF-IDF ç›¸ä¼¼åº¦ï¼ˆé€‚ç”¨äº 10k+ è®ºæ–‡ï¼‰...")
        vectorizer = TfidfVectorizer(
            max_features=10000,
            stop_words="english",
            lowercase=True,
            ngram_range=(1, 2),  # åŒ…å« bigram æå‡æ•ˆæœ
        )
        tfidf_matrix = vectorizer.fit_transform(self.texts)
        print(f"TF-IDF çŸ©é˜µå½¢çŠ¶: {tfidf_matrix.shape}")

        # è®¡ç®—ç¨€ç–çŸ©é˜µçš„æˆå¯¹ç›¸ä¼¼åº¦ï¼ˆå†…å­˜å‹å¥½ï¼‰
        # æ³¨æ„ï¼š10k x 10k çŸ©é˜µéœ€çº¦ 800MB å†…å­˜ï¼ˆfloat64ï¼‰ï¼Œå¯æ¥å—
        cosine_sim = cosine_similarity(tfidf_matrix)
        results = []

        n = len(self.df)
        for i in tqdm(range(n), desc="ç­›é€‰ç›¸ä¼¼è®ºæ–‡"):
            # è·å–ä¸è®ºæ–‡ i æœ€ç›¸ä¼¼çš„ top_k ç¯‡ï¼ˆæ’é™¤è‡ªå·±ï¼‰
            sim_scores = cosine_sim[i]
            sim_scores[i] = -1  # æ’é™¤è‡ªèº«
            top_indices = np.argsort(sim_scores)[::-1][:top_k]
            for j in top_indices:
                sim = sim_scores[j]
                if sim >= threshold:
                    results.append(
                        {
                            "id1": self.df.iloc[i]["id"],
                            "id2": self.df.iloc[j]["id"],
                            "title1": self.df.iloc[i]["title"],
                            "title2": self.df.iloc[j]["title"],
                            "similarity": float(sim),
                            "method": "TF-IDF",
                        }
                    )
                else:
                    break  # åç»­æ›´å°ï¼Œå¯æå‰ç»ˆæ­¢ï¼ˆå› å·²æ’åºï¼‰

        if output_path:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"âœ… TF-IDF ç»“æœå·²ä¿å­˜è‡³: {output_path}")

        return results

    # ================ æ–¹æ³•2ï¼šSentence-BERT é«˜ç²¾åº¦è®¡ç®— ================
    def compute_sbert_similarity(
        self, top_k=5, threshold=0.6, model_name="all-MiniLM-L6-v2", output_path=None
    ):
        """
        ä½¿ç”¨ Sentence-BERT è®¡ç®—é«˜ç²¾åº¦è¯­ä¹‰ç›¸ä¼¼åº¦
        :param top_k: æ¯ç¯‡è¿”å› top_k ç›¸ä¼¼
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        :param model_name: SBERT æ¨¡å‹åç§°
        :param output_path: ä¿å­˜è·¯å¾„
        :return: list of dict
        """
        print(f"ğŸ§  æ­£åœ¨åŠ è½½ SBERT æ¨¡å‹: {model_name}...")
        model = SentenceTransformer(model_name)

        print("ğŸ”¤ æ­£åœ¨ç¼–ç æ‰€æœ‰è®ºæ–‡ï¼ˆæ ‡é¢˜+æ‘˜è¦ï¼‰...")
        embeddings = model.encode(self.texts, show_progress_bar=True, batch_size=128)

        print("ğŸ” è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆé«˜ç²¾åº¦ï¼‰...")
        cosine_sim = cosine_similarity(embeddings)
        results = []

        n = len(self.df)
        for i in tqdm(range(n), desc="æ¨èç›¸ä¼¼è®ºæ–‡"):
            sim_scores = cosine_sim[i]
            sim_scores[i] = -1
            top_indices = np.argsort(sim_scores)[::-1][:top_k]
            for j in top_indices:
                sim = sim_scores[j]
                if sim >= threshold:
                    results.append(
                        {
                            "id1": self.df.iloc[i]["id"],
                            "id2": self.df.iloc[j]["id"],
                            "title1": self.df.iloc[i]["title"],
                            "title2": self.df.iloc[j]["title"],
                            "similarity": float(sim),
                            "method": "SBERT",
                        }
                    )
                else:
                    break

        if output_path:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"âœ… SBERT ç»“æœå·²ä¿å­˜è‡³: {output_path}")

        return results


# ================ ä½¿ç”¨ç¤ºä¾‹ ================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è®ºæ–‡ç›¸ä¼¼åº¦è®¡ç®—å·¥å…·")
    parser.add_argument("--data", type=str, required=True, help="è®ºæ–‡æ•°æ®æ–‡ä»¶è·¯å¾„ (CSV/JSON)")
    parser.add_argument("--mode", type=str, choices=["tfidf", "sbert", "both"], default="both")
    parser.add_argument("--tfidf_out", type=str, default="tfidf_results.json")
    parser.add_argument("--sbert_out", type=str, default="sbert_results.json")
    parser.add_argument("--top_k", type=int, default=5)
    parser.add_argument("--tfidf_threshold", type=float, default=0.4)
    parser.add_argument("--sbert_threshold", type=float, default=0.6)

    args = parser.parse_args()

    # åˆå§‹åŒ–
    ps = PaperSimilarity(args.data, text_field="combined")

    if args.mode in ["tfidf", "both"]:
        tfidf_results = ps.compute_tfidf_similarity(
            top_k=args.top_k, threshold=args.tfidf_threshold, output_path=args.tfidf_out
        )
        print(f"ğŸ” TF-IDF æ‰¾åˆ° {len(tfidf_results)} å¯¹ç›¸ä¼¼è®ºæ–‡")

    if args.mode in ["sbert", "both"]:
        sbert_results = ps.compute_sbert_similarity(
            top_k=args.top_k, threshold=args.sbert_threshold, output_path=args.sbert_out
        )
        print(f"ğŸ§  SBERT æ‰¾åˆ° {len(sbert_results)} å¯¹ç›¸ä¼¼è®ºæ–‡")
